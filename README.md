# Selenium_Assignment

# Automated Job Search Agent

This is an  automated internship search agent that scrapes LinkedIn job postings and uses Google AI Studio or Gemeni to analyze each one against a candidate profile, generating fit scores, CV tips, and personalized cover letters.

---

## How It Works

### Step 1 — Building the Profile
Before running any code, I manually compiled all my CVs, transcripts, and course syllabuses into a single folder. I used the **extract_data** to extract all the text from these documents, then fed that text into Claude (AI) to generate a JSON file called `profile.json`. This file contains my education, skills, experience, languages, and internship preferences etc. 

### Step 2 — Saving LinkedIn Session
Since LinkedIn requires login, the `session_manager.py` script opens a Chrome window, lets you log in manually, and then saves your session cookies locally so the scraper can reuse them without logging in every time.

### Step 3 — Scraping LinkedIn
`linkedin_scraper.py` uses Selenium to scroll through your LinkedIn recommended jobs feed, scraping job titles, companies, locations, and links. It keeps track of already-scraped jobs so it only collects new ones on each run. It saves the new jobs in the linkedin_jobs json file that gemeni will then use. 

### Step 4 — AI Analysis
`ai_processor.py` takes the scraped jobs and your profile and sends each one to Gemini AI. For each relevant job it returns:
- A fit score (1–10)
- A fit summary
- Key skill gaps
- CV tips tailored to that role
- A personalized cover letter

Results are saved as both `job_leads.json` and `job_leads.md`.

### Step 5 — Running Everything
`main.py` runs everything using Python threading and a job queue. It runs the scraper and processor sequentially in a thread, using a lock to prevent race conditions on shared files.

---

## Project Structure

```
├── main.py                  # Entry point — runs scraper then processor
├── session_manager.py       # Save LinkedIn login session
├── linkedin_scraper.py      # Scrapes LinkedIn job listings
├── ai_processor.py          # Analyzes jobs with Gemini AI
├── data/
│   ├── profile.json         # Candidate profile
│   └── linkedin_cookies.pkl # Generated by session_manager
└── outputs/
    ├── job_leads.json        # Generated output
    └── job_leads.md          # Generated output 
```

---

## Setup & Usage

### 1. Install dependencies
```bash
pip install selenium google-genai
```

### 2. Get a Gemini API key
Go to [aistudio.google.com/apikey](https://aistudio.google.com/apikey), create a free API key, and paste it into `ai_processor.py`:
```python
client = genai.Client(api_key="YOUR_API_KEY_HERE")
```

### 3. Create your profile
Create a `data/` folder and add a `profile.json` file with your details. You can compile your CV and course syllabuses, extract the text, and ask an AI to structure it into JSON with fields like:
```json
{
  "contact_info": { "name": "Your Name" },
  "education": [...],
  "skills": [...],
  "languages": [...],
  "internship_preferences": {
    "locations": ["Madrid", "Remote"],
    "start_date": "June 2026",
    "duration": "3 months"
  }
}
```

### 4. Save your LinkedIn session
```bash
python session_manager.py
```
A Chrome window will open. Log in to LinkedIn manually, then press Enter in the terminal. Your session is now saved.

### 5. Run the agent
```bash
python main.py
```
This will scrape new jobs and analyze them. Results will appear in `outputs/job_leads.md`.

---

## OS Concepts Used
- **Threads** — the scraper and processor run inside a worker thread
- **Queue** — jobs are managed with `queue.Queue`, similar to the in-class exercise
- **Mutex/Lock** — `threading.Lock` prevents race conditions when reading/writing shared files
- **Processes** — each script is launched as a subprocess
- **Selenium/WebDriver** — browser automation via ChromeDriver

---

## Notes
- Re-running the agent will only scrape and analyze **new** jobs — already processed ones are skipped
